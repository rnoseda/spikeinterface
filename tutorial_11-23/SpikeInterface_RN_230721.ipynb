{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpikeInterface v0.98.2 - Adapted by Rodrigo Noseda - July 2023\n",
    "\n",
    "SpikeInterface to analyze a 128-channel dataset from from Cambridge Neurotech Probes. \n",
    "The dataset is extracted using open-ephys DAQ and Bonsai-rx (in .bin).\n",
    "Event_timestamps need some work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Preparation <a class=\"anchor\" id=\"preparation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpikeInterface version: 0.98.2\n"
     ]
    }
   ],
   "source": [
    "import spikeinterface as si\n",
    "import spikeinterface.extractors as se \n",
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface.postprocessing as spost\n",
    "import spikeinterface.qualitymetrics as sqm\n",
    "import spikeinterface.comparison as sc\n",
    "import spikeinterface.exporters as sexp\n",
    "import spikeinterface.widgets as sw\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "from pathlib import Path\n",
    "import spikeinterface_gui as sigui\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "%matplotlib widget\n",
    "print(f\"SpikeInterface version: {si.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading recording and probe information <a class=\"anchor\" id=\"loading\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# file paths\n",
    "base_folder = Path('.')\n",
    "data_folder = Path(\"C:/Users/rodri/Documents/Bonsai-RN/Bonsai_DataRN/2023_3_21/\")\n",
    "#Pasted directly from explorer \"C:\\Users\\rodri\\Documents\\Bonsai-RN\\Bonsai_DataRN\\2023_3_21\\\"\n",
    "recording_file = data_folder / \"RawEphysData_64Ch_F-Probe10.bin\"\n",
    "# parameters to load the bin/dat format\n",
    "num_channels = 64 #must know apriori; modify in probe below accordingly.\n",
    "sampling_frequency = 30000\n",
    "gain_to_uV = 0.195\n",
    "offset_to_uV = 0\n",
    "t_starts = 0\n",
    "dtype = \"float32\"\n",
    "time_axis = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading timestamps and convert them into ms as a list of single (electrical) or double (start/stop-brush) events <a class=\"anchor\" id=\"loading\"></a>\n",
    "Single events and tone 10s, 20s events, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "start_time = data_folder / \"StartRecording_Time_0.csv\"\n",
    "#events_file = data_folder / \"Events_8.csv\"\n",
    "event_time = data_folder / \"Events_10s_Tone_0.csv\"\n",
    "#event_tone20s = data_folder / \"Events_20s_Tone_0.csv\"\n",
    "#Electrical TTL's from 3 channels (eventually). If only 1 channel is used, only that file will have data.\n",
    "#event_TTL0 = data_folder / \"TTL0_0.csv\"\n",
    "#event_TTL1 = data_folder / \"TTL1_0.csv\"\n",
    "#event_TTL2 = data_folder / \"TTL2_0.csv\"\n",
    "\n",
    "# Open the start time file and read the start time\n",
    "with open(start_time, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    start_time_str = next(reader)[0]\n",
    "start_time = datetime.strptime(start_time_str, '%H:%M:%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "input_filename = 'times.csv'\n",
    "output_filename = 'times_ms.csv'\n",
    "\n",
    "times_in_ms = []\n",
    "\n",
    "# Read the times from the CSV and convert them to milliseconds\n",
    "with open(input_filename, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        # Convert time string to datetime object\n",
    "        time_obj = datetime.strptime(row[0], '%H:%M:%S.%f')\n",
    "        # Convert to milliseconds\n",
    "        milliseconds = (time_obj.hour * 3600 + time_obj.minute * 60 + time_obj.second) * 1000 + time_obj.microsecond // 1000\n",
    "        times_in_ms.append([milliseconds])\n",
    "\n",
    "# Write the converted times back to a new CSV file\n",
    "with open(output_filename, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(times_in_ms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize an empty list to hold the event times\n",
    "event_times_ms = []\n",
    "\n",
    "# Iterate over the event_time files\n",
    "for i in range(10):\n",
    "    with open(event_time, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        \n",
    "        # For each time in the file, calculate the time difference in milliseconds\n",
    "        for row in reader:\n",
    "            event_time = datetime.strptime(row[0], '%H:%M:%S')\n",
    "            time_difference = event_time - start_time\n",
    "            milliseconds = time_difference.total_seconds() * 1000\n",
    "            event_times_ms.append(milliseconds)\n",
    "\n",
    "# Write the event times to a new CSV file\n",
    "with open('events_ms.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for time in event_times_ms:\n",
    "        writer.writerow([time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = your_list1\n",
    "triggers = your_list2 + your_list3 #get csv file?.\n",
    "print(len(your_list1))\n",
    "print(len(your_list2))\n",
    "print(len(triggers))\n",
    "print(triggers)\n",
    "trigger1 = triggers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "recording = si.read_binary(recording_file, num_chan=num_channels,sampling_frequency=sampling_frequency,\n",
    "                           dtype=dtype, gain_to_uV=gain_to_uV, offset_to_uV=offset_to_uV, \n",
    "                           time_axis=time_axis, is_filtered=False)\n",
    "\n",
    "channel_ids = recording.get_channel_ids()\n",
    "fs = recording.get_sampling_frequency()\n",
    "num_chan = recording.get_num_channels()\n",
    "num_segments = recording.get_num_segments()\n",
    "trace_snippet = recording.get_traces(start_frame=int(fs*0), end_frame=int(fs*180))\n",
    "trace_total_duration = recording.get_total_duration()\n",
    "trace_total_samples = recording.get_total_samples()\n",
    "\n",
    "print(f'Channel ids: {channel_ids}')\n",
    "print(f'Sampling frequency: {fs}')\n",
    "print(f'Number of channels: {num_chan}')\n",
    "print(f\"Number of segments: {num_segments}\")\n",
    "print('Trace Shape:', trace_snippet.shape)\n",
    "print('Trace Total Duration:', trace_total_duration)\n",
    "print('Trace Total Samples:', trace_total_samples)\n",
    "recording_1min_slice = recording.frame_slice(start_frame=int(0), end_frame=int(fs*60)) #in samples=30000samples*60sec (fs*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import probeinterface as pi\n",
    "from probeinterface import Probe, ProbeGroup\n",
    "from probeinterface import generate_linear_probe, get_probe, generate_multi_shank\n",
    "from probeinterface import combine_probes\n",
    "from probeinterface import generate_multi_columns_probe\n",
    "from probeinterface.plotting import plot_probe, plot_probe_group \n",
    "from probeinterface import generate_dummy_probe\n",
    "from probeinterface import write_probeinterface, read_probeinterface\n",
    "from probeinterface import write_prb, read_prb\n",
    "print(f\"ProbeInterface version: {pi.__version__}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run code below get the probe from library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probeF64 = pi.get_probe(manufacturer='cambridgeneurotech',\n",
    "                     probe_name= 'ASSY-158-F')#probe object from library comes with contact and shank info.\n",
    "device_channel_indices = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,\n",
    "               21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,\n",
    "               41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63] #Modify accordingly.\n",
    "probeF64.set_device_channel_indices(device_channel_indices)\n",
    "print(probeF64)\n",
    "print(probeF64.device_channel_indices)\n",
    "print(probeF64.contact_ids)\n",
    "print(probeF64.shank_ids)\n",
    "\n",
    "plot_probe(probeF64, with_channel_index=True, with_device_index=True, with_contact_id=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device_channel_indices = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,\n",
    "#               21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,\n",
    "#               41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,\n",
    "#               61,62,63] #based on how recording was saved in Bonsai (mapped channels saved)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probe now has contact ids `id#` and device ids `dev#`! Note that also the `shank_id` is loaded with the probe. We can also visualize the probe information as a `pandas` dataframe:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "probeF64.to_dataframe(complete=True).loc[:, [\"contact_ids\", \"shank_ids\", \"device_channel_indices\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A probe (prb) or `probeinterface` object can be loaded directly to a SI recording object:\n",
    "-In the case below, a group is formed from each shank - 'by_shank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "recording_prb = recording.set_probe(probeF64, group_mode=\"by_shank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "A = recording_prb.get_channel_ids()\n",
    "recording_slice = recording_prb.channel_slice(A[0:63])\n",
    "w_ts = sw.plot_timeseries(recording_slice, channel_ids=None, order_channel_by_depth=False,\n",
    "                          time_range=(0, 2), show_channel_ids= True, backend=\"matplotlib\", clim=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After loading the probe we now have some new properties: `contact_vector`, `location`, and `group`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing <a class=\"anchor\" id=\"preprocessing\"></a>\n",
    "\n",
    "All preprocessing modules return new `RecordingExtractor` objects that apply the underlying preprocessing function. This allows users to access the preprocessed data in the same way as the raw data. We will focus only on the first shank (group `0`) for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "start_time = start_time_file #'StartRecording_Time_0.csv\n",
    "event_file_pre = event_file1 #'TTL0_0.csv'\n",
    "event_file_post = event_file2 #'TTL1_0.csv'\n",
    "\n",
    "# Read the start time from the first CSV\n",
    "with open(start_time, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    start_time_str = next(reader)[0]  # Assuming the start time is the first value in the CSV\n",
    "    start_time = datetime.strptime(start_time_str, '%H:%M:%S')  # Assuming time is in 'HH:MM:SS' format\n",
    "\n",
    "differences = []\n",
    "\n",
    "# Iterate through the enumerated event files\n",
    "for i in range(10):\n",
    "    event_filename = f'event_times_{i}.csv'\n",
    "    with open(event_filename, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        event_times = [datetime.strptime(row[0], '%H:%M:%S') for row in reader]\n",
    "        differences.extend([(event_time - start_time).seconds for event_time in event_times])\n",
    "\n",
    "# Write all the differences to a new CSV file\n",
    "with open('events_ms.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for difference in differences:\n",
    "        writer.writerow([difference])\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "import csv\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "with open(start_time, newline='') as h:\n",
    "    reader1 = csv.reader(h)\n",
    "    your_list1 = list(reader1)\n",
    "\n",
    "with open(event_file_pre, newline='') as f:\n",
    "    reader2 = csv.reader(f)\n",
    "    your_list2 = list(reader2)\n",
    "\n",
    "with open(event_file_post, newline='') as g:\n",
    "    reader3 = csv.reader(g)\n",
    "    your_list3 = list(reader3)\n",
    "    \n",
    "start = your_list1\n",
    "triggers = your_list2 + your_list3 #get csv file?.\n",
    "print(len(your_list1))\n",
    "print(len(your_list2))\n",
    "print(len(triggers))\n",
    "print(triggers)\n",
    "trigger1 = triggers[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "recordings_by_group = recording_prb.split_by(\"group\")\n",
    "recording_to_process = recordings_by_group[0]\n",
    "recording_to_process.get_num_channels()\n",
    "recording_f = spre.bandpass_filter(recording_to_process, freq_min=300, freq_max=6000)\n",
    "recording_cmr = spre.common_reference(recording_f, reference='global', operator='median')\n",
    "\n",
    "recording_removeart = spre.remove_artifacts(recording_cmr, list_triggers=trigger, ms_before=0.5, ms_after=3.0, \n",
    "                      mode='cubic', fit_sample_spacing=1.0, list_labels=None, artifacts=None, \n",
    "                      sparsity=None, scale_amplitude=False, time_jitter=0, waveforms_kwargs={'allow_unfiltered': True, 'mode': 'memory'})\n",
    "\n",
    "#recording_removeart = spre.RemoveArtifactsRecording(recording_prb, list_triggers=triggers, ms_before=0.5, ms_after=3)\n",
    "print(recording_to_process)\n",
    "print(recording_cmr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take only 1 min. for demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Since we are going to spike sort the data, let's first cut out a 5-minute recording, to speed up computations.\n",
    "\n",
    "We can easily do so with the `frame_slice()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#fs = recording_cmr.get_sampling_frequency()\n",
    "recording_sub = recording_cmr.frame_slice(start_frame=0*fs, end_frame=180*fs)\n",
    "print(recording_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Saving and loading SpikeInterface objects <a class=\"anchor\" id=\"save-load\"></a>\n",
    "\n",
    "All operations in SpikeInterface are *lazy*, meaning that they are not performed if not needed. This is why the creation of our filter recording was almost instantaneous. However, to speed up further processing, we might want to **save** it to a file and perform those operations (eg. filters, CMR, etc.) at once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "job_kwargs = dict(n_jobs=-1, chunk_duration=\"1s\", progress_bar=True)\n",
    "global_job_kwargs = dict(n_jobs=-1, chunk_duration=\"1s\", progress_bar=True)\n",
    "#set_global_job_kwargs(**global_job_kwargs)\n",
    "#print(get_global_job_kwargs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if (base_folder / \"preprocessed\").is_dir():\n",
    "    recording_saved = si.load_extractor(base_folder / \"preprocessed\")\n",
    "else:\n",
    "    recording_saved = recording_cmr.save(folder=base_folder / \"preprocessed\", **job_kwargs)\n",
    "    \n",
    "print(recording_saved)\n",
    "print(f'Cached channels ids: {recording_saved.get_channel_ids()}')\n",
    "print(f'Channel groups after caching: {recording_saved.get_channel_groups()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The `traces_cached_seg0.raw` contains the processed raw data, while the `.json` files include information on how to reload the binary file. The `provenance.json` includes the information of the recording before saving it to a binary file, and the `probe.json` represents the probe object. The `save` returns a new *cached* recording that has all the previously loaded information: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After saving the SI object, we can easily load it back in a new session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "recording_loaded = si.load_extractor(base_folder/\"preprocessed\")\n",
    "print(f'Loaded channels ids: {recording_loaded.get_channel_ids()}')\n",
    "print(f'Channel groups after loading: {recording_loaded.get_channel_groups()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can double check that the traces are exactly the same as the `recording_saved` that we saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2)\n",
    "w_saved = sw.plot_timeseries(recording_saved, ax=axs[0])\n",
    "w_loaded = sw.plot_timeseries(recording_loaded, ax=axs[1])\n",
    "axs[0].set_title(\"Saved\")\n",
    "axs[1].set_title(\"Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**IMPORTANT**: the same saving mechanisms are available also for all SortingExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Spike sorting <a class=\"anchor\" id=\"spike-sorting\"></a>\n",
    "\n",
    "We can now run spike sorting on the above recording. We will use different spike sorters for this demonstration, to show how easy SpikeInterface makes it easy to interchengably run different sorters :)\n",
    "\n",
    "Let's first check the installed sorters in `SpikeInterface` to see if `tridesclous` is available. Then we can then check the `tridesclous` default parameters.\n",
    "We will sort the bandpass cached filtered recording the `recording_saved` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "ss.installed_sorters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "default_SC2_params = ss.get_default_sorter_params('spykingcircus2')\n",
    "# Parameters can be changed by single arguments: \n",
    "#default_TDC_params['detect_threshold'] = 3 \n",
    "#default_TDC_params['freq_max'] = 6000\n",
    "#default_TDC_params['freq_min'] = 300\n",
    "pprint(default_SC2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run spike sorting on entire recording\n",
    "sorting_SC2 = ss.run_sorter('spykingcircus2', recording_loaded, \n",
    "                            output_folder=base_folder / 'results_SC2_7-21-23', \n",
    "                            n_jobs=-1, chunk_size=30000, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_SC2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "SpikeInterface ensures full provenance of the spike sorting pipeline. Upon running a spike sorter, a `spikeinterface_params.json` file is saved in the `output_folder`. This contains a `.json` version of the recording and all the input parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can use `spikewidgets` functions for some quick visualizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "w_rs = sw.plot_rasters(sorting_SC2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Extracting waveforms <a class=\"anchor\" id=\"waveforms\"></a>\n",
    "\n",
    "The core module uses `WaveformExtractor` fro extracting waveforms from paired recording-sorting objects. It retrieves waveforms and templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "si.extract_waveforms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_all = si.extract_waveforms(recording_loaded, sorting_SC2, folder=base_folder / \"wf_SC2b_all\", \n",
    "                              max_spikes_per_unit=None, load_if_exists=True, **job_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for unit in sorting_SC2.get_unit_ids():\n",
    "    waveforms = we_all.get_waveforms(unit_id=unit)\n",
    "    spiketrain = sorting_SC2.get_unit_spike_train(unit)\n",
    "    print(f\"Unit {unit} - num waveforms: {waveforms.shape[0]} - num spikes: {len(spiketrain)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now waveforms have been extracted for all spikes! Let's move on to explore the postprocessing capabilities of the `postprocessing` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 7. Postprocessing <a class=\"anchor\" id=\"postprocessing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postprocessing spike sorting results ranges from computing additional information, such as spike amplitudes and Principal Component Analisys (PCA) scores, to computing features of the extracellular waveforms, similarity between templates and crosscorrelograms. All of this is possible with the `postprocessing` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### PCA scores\n",
    "\n",
    "PCA scores can be easily computed with the `compute_principal_components()` function. Similarly to the `extract_waveforms`, the function returns an object of type `WaveformPrincipalComponent` that allows to retrieve all pc scores on demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_all.get_available_extension_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = spost.compute_principal_components(we_all, n_components=3, load_if_exists=True)\n",
    "amplitudes = spost.compute_spike_amplitudes(we_all, outputs=\"by_unit\", load_if_exists=True, \n",
    "                                            **job_kwargs)\n",
    "unit_locations = spost.compute_unit_locations(we_all, method=\"monopolar_triangulation\", load_if_exists=True)\n",
    "spike_locations = spost.compute_spike_locations(we_all, method=\"monopolar_triangulation\", load_if_exists=True,\n",
    "                                                **job_kwargs)\n",
    "ccgs, bins = spost.compute_correlograms(we_all)\n",
    "template_metrics = spost.calculate_template_metrics(we_all)\n",
    "sparsity_radius = spost.get_template_channel_sparsity(we_all, method=\"radius\", radius_um=50)\n",
    "similarity = spost.compute_template_similarity(we_all)\n",
    "\n",
    "qm = sqm.compute_quality_metrics(we_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets\n",
    "sw.plot_unit_locations(we_all, backend=\"ipywidgets\")\n",
    "sw.plot_spike_locations(we_all, backend=\"ipywidgets\")\n",
    "sw.plot_amplitudes(we_all, backend=\"ipywidgets\")\n",
    "sw.plot_autocorrelograms(we_all, unit_ids=sorting_SC2.unit_ids[:4])\n",
    "sw.plot_crosscorrelograms(we_all, unit_ids=sorting_SC2.unit_ids[:4])\n",
    "sw.plot_unit_templates(we_all, backend=\"matplotlib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "isi_viol_thresh = 0.2\n",
    "amp_cutoff_thresh = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A straightforward way to filter a pandas dataframe is via the `query`.\n",
    "We first define our query (make sure the names match the column names of the dataframe):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "our_query = f\"amplitude_cutoff < {amp_cutoff_thresh} & isi_violations_ratio < {isi_viol_thresh}\"\n",
    "print(our_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "and then we can use the query to select units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "keep_units = qm.query(our_query)\n",
    "keep_unit_ids = keep_units.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_auto = sorting_SC2.select_units(keep_unit_ids)\n",
    "print(f\"Number of units before curation: {len(sorting_SC2.get_unit_ids())}\")\n",
    "print(f\"Number of units after curation: {len(sorting_auto.get_unit_ids())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Viewers <a class=\"anchor\" id=\"viewers\"></a>\n",
    "\n",
    "Let's check put the `spikeinterface-gui` to explore our spike sorting results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpikeInterface GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!sigui waveforms/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Summary - SortingView"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sortingview` backend requires an additional step to configure the transfer of the data to be plotted to the cloud. \n",
    "\n",
    "See documentation [here](https://spikeinterface.readthedocs.io/en/latest/module_widgets.html): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 11. Exporters <a class=\"anchor\" id=\"exporters\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Export to Phy for manual curation\n",
    "\n",
    "To perform manual curation we can export the data to [Phy](https://github.com/cortex-lab/phy). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sexp.export_to_phy(we_all, output_folder=base_folder / 'phy_SC2b', \n",
    "                   **job_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "!phy template-gui phy_SC2b/params.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After curating the results we can reload it using the `PhySortingExtractor` and exclude the units that we labeled as `noise`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_phy_curated = se.PhySortingExtractor(base_folder / 'phy_SC2/', exclude_cluster_groups=['noise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of units before curation: {len(sorting_SC2.get_unit_ids())}\")\n",
    "print(f\"Number of units after curation: {len(sorting_phy_curated.get_unit_ids())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "b = np.load(base_folder / 'phy_SC2b/spike_clusters.npy')\n",
    "print(b)\n",
    "print(len(b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('SI-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "e796914cfda0b008681a29da637f213a2ba3e2974d7c5b0074900a81a5c831d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
