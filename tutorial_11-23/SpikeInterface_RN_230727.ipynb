{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpikeInterface v0.98.2 - Adapted by Rodrigo Noseda - July 2023\n",
    "\n",
    "SpikeInterface to analyze a 128-channel dataset from from Cambridge Neurotech Probes. \n",
    "The dataset is extracted using open-ephys DAQ and Bonsai-rx (in .bin).\n",
    "Event_timestamps need some work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Preparation <a class=\"anchor\" id=\"preparation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import spikeinterface as si\n",
    "import spikeinterface.extractors as se \n",
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface.postprocessing as spost\n",
    "import spikeinterface.qualitymetrics as sqm\n",
    "import spikeinterface.comparison as sc\n",
    "import spikeinterface.exporters as sexp\n",
    "import spikeinterface.widgets as sw\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "from pathlib import Path\n",
    "import spikeinterface_gui as sigui\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "%matplotlib widget\n",
    "print(f\"SpikeInterface version: {si.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading recording and probe information <a class=\"anchor\" id=\"loading\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# file paths\n",
    "base_folder = Path('.')\n",
    "data_folder = Path(\"C:/Users/rodri/Documents/Bonsai-RN/Bonsai_DataRN/2023_3_21/\")\n",
    "#Pasted directly from explorer \"C:\\Users\\rodri\\Documents\\Bonsai-RN\\Bonsai_DataRN\\2023_3_21\\\"\n",
    "recording_file = data_folder / \"RawEphysData_64Ch_F-Probe10.bin\"\n",
    "# parameters to load the bin/dat format\n",
    "num_channels = 64 #must know apriori; modify in probe below accordingly.\n",
    "sampling_frequency = 30000\n",
    "gain_to_uV = 0.195\n",
    "offset_to_uV = 0\n",
    "t_starts = 0\n",
    "dtype = \"float32\"\n",
    "time_axis = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "recording = si.read_binary(recording_file, num_chan=num_channels,sampling_frequency=sampling_frequency,\n",
    "                           dtype=dtype, gain_to_uV=gain_to_uV, offset_to_uV=offset_to_uV, \n",
    "                           time_axis=time_axis, is_filtered=False)\n",
    "\n",
    "channel_ids = recording.get_channel_ids()\n",
    "fs = recording.get_sampling_frequency()\n",
    "num_chan = recording.get_num_channels()\n",
    "num_segments = recording.get_num_segments()\n",
    "trace_snippet = recording.get_traces(start_frame=int(fs*0), end_frame=int(fs*180))\n",
    "trace_total_duration = recording.get_total_duration()\n",
    "trace_total_samples = recording.get_total_samples()\n",
    "\n",
    "print(f'Channel ids: {channel_ids}')\n",
    "print(f'Sampling frequency: {fs}')\n",
    "print(f'Number of channels: {num_chan}')\n",
    "print(f\"Number of segments: {num_segments}\")\n",
    "print('Trace Shape:', trace_snippet.shape)\n",
    "print('Trace Total Duration:', trace_total_duration)\n",
    "print('Trace Total Samples:', trace_total_samples)\n",
    "#recording_1min_slice = recording.frame_slice(start_frame=int(0), end_frame=int(fs*120)) \n",
    "#sw.plot_timeseries(recording_1min_slice, time_range=(40, 50)) #in samples=30000samples*60sec (fs*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list_triggers = [42, 43]\n",
    "recording_clean = spre.remove_artifacts(recording, list_triggers, ms_before=100, ms_after=1000, mode='zeros', \n",
    "                                              fit_sample_spacing=1.0, list_labels=None, artifacts=None, sparsity=None, \n",
    "                                              scale_amplitude=False, time_jitter=0, \n",
    "                                              waveforms_kwargs={'allow_unfiltered': True, 'mode': 'memory'})\n",
    "start_frame = 42\n",
    "end_frame = 45\n",
    "list_periods = (start_frame, end_frame)\n",
    "rec_cut = spre.silence_periods(recording, list_periods, mode='zeros')\n",
    "\n",
    "sw.plot_timeseries(recording, time_range=(40, 50)) #in samples=30000samples*60sec (fs*60)\n",
    "sw.plot_timeseries(recording_clean, time_range=(40, 50))\n",
    "sw.plot_timeseries(rec_cut, time_range=(40, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import probeinterface as pi\n",
    "from probeinterface import Probe, ProbeGroup\n",
    "from probeinterface import generate_linear_probe, get_probe, generate_multi_shank\n",
    "from probeinterface import combine_probes\n",
    "from probeinterface import generate_multi_columns_probe\n",
    "from probeinterface.plotting import plot_probe, plot_probe_group \n",
    "from probeinterface import generate_dummy_probe\n",
    "from probeinterface import write_probeinterface, read_probeinterface\n",
    "from probeinterface import write_prb, read_prb\n",
    "print(f\"ProbeInterface version: {pi.__version__}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run code below get the probe from library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probeF64 = pi.get_probe(manufacturer='cambridgeneurotech',\n",
    "                     probe_name= 'ASSY-158-F')#probe object from library comes with contact and shank info.\n",
    "device_channel_indices = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,\n",
    "               21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,\n",
    "               41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63] #Modify accordingly.\n",
    "probeF64.set_device_channel_indices(device_channel_indices)\n",
    "print(probeF64)\n",
    "print(probeF64.device_channel_indices)\n",
    "print(probeF64.contact_ids)\n",
    "print(probeF64.shank_ids)\n",
    "\n",
    "plot_probe(probeF64, with_channel_index=True, with_device_index=True, with_contact_id=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device_channel_indices = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,\n",
    "#               21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,\n",
    "#               41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,\n",
    "#               61,62,63] #based on how recording was saved in Bonsai (mapped channels saved)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probe now has contact ids `id#` and device ids `dev#`! Note that also the `shank_id` is loaded with the probe. We can also visualize the probe information as a `pandas` dataframe:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "probeF64.to_dataframe(complete=True).loc[:, [\"contact_ids\", \"shank_ids\", \"device_channel_indices\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A probe (prb) or `probeinterface` object can be loaded directly to a SI recording object:\n",
    "-In the case below, a group is formed from each shank - 'by_shank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "recording_prb = recording.set_probe(probeF64, group_mode=\"by_shank\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "A = recording_prb.get_channel_ids()\n",
    "recording_slice = recording_prb.channel_slice(A[0:3])\n",
    "w_ts = sw.plot_timeseries(recording_slice, channel_ids=None, order_channel_by_depth=False,\n",
    "                          time_range=(42, 44), show_channel_ids= True, backend=\"matplotlib\", clim=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After loading the probe we now have some new properties: `contact_vector`, `location`, and `group`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing <a class=\"anchor\" id=\"preprocessing\"></a>\n",
    "\n",
    "All preprocessing modules return new `RecordingExtractor` objects that apply the underlying preprocessing function. This allows users to access the preprocessed data in the same way as the raw data. We will focus only on the first shank (group `0`) for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "recordings_by_group = recording_prb.split_by(\"group\")\n",
    "recording_to_process = recordings_by_group[0]\n",
    "recording_to_process.get_num_channels()\n",
    "recording_f = spre.bandpass_filter(recording_to_process, freq_min=400, freq_max=5000)\n",
    "recording_cmr = spre.common_reference(recording_f, reference='global', operator='median')\n",
    "#recording_removeart = spre.RemoveArtifactsRecording(recording_prb, list_triggers=triggers, ms_before=0.5, ms_after=3)\n",
    "print(recording_to_process)\n",
    "print(recording_cmr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take only 1 min. for demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Since we are going to spike sort the data, let's first cut out a 5-minute recording, to speed up computations.\n",
    "\n",
    "We can easily do so with the `frame_slice()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#fs = recording_cmr.get_sampling_frequency()\n",
    "recording_sub = recording_cmr.frame_slice(start_frame=0*fs, end_frame=180*fs)\n",
    "print(recording_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Saving and loading SpikeInterface objects <a class=\"anchor\" id=\"save-load\"></a>\n",
    "\n",
    "All operations in SpikeInterface are *lazy*, meaning that they are not performed if not needed. This is why the creation of our filter recording was almost instantaneous. However, to speed up further processing, we might want to **save** it to a file and perform those operations (eg. filters, CMR, etc.) at once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "job_kwargs = dict(n_jobs=-1, chunk_duration=\"1s\", progress_bar=True)\n",
    "global_job_kwargs = dict(n_jobs=-1, chunk_duration=\"1s\", progress_bar=True)\n",
    "#set_global_job_kwargs(**global_job_kwargs)\n",
    "#print(get_global_job_kwargs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if (base_folder / \"preprocessed\").is_dir():\n",
    "    recording_saved = si.load_extractor(base_folder / \"preprocessed\")\n",
    "else:\n",
    "    recording_saved = recording_cmr.save(folder=base_folder / \"preprocessed\", **job_kwargs)\n",
    "    \n",
    "print(recording_saved)\n",
    "print(f'Cached channels ids: {recording_saved.get_channel_ids()}')\n",
    "print(f'Channel groups after caching: {recording_saved.get_channel_groups()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The `traces_cached_seg0.raw` contains the processed raw data, while the `.json` files include information on how to reload the binary file. The `provenance.json` includes the information of the recording before saving it to a binary file, and the `probe.json` represents the probe object. The `save` returns a new *cached* recording that has all the previously loaded information: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After saving the SI object, we can easily load it back in a new session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "recording_loaded = si.load_extractor(base_folder/\"preprocessed\")\n",
    "print(f'Loaded channels ids: {recording_loaded.get_channel_ids()}')\n",
    "print(f'Channel groups after loading: {recording_loaded.get_channel_groups()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can double check that the traces are exactly the same as the `recording_saved` that we saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2)\n",
    "w_saved = sw.plot_timeseries(recording_saved, ax=axs[0])\n",
    "w_loaded = sw.plot_timeseries(recording_loaded, ax=axs[1])\n",
    "axs[0].set_title(\"Saved\")\n",
    "axs[1].set_title(\"Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**IMPORTANT**: the same saving mechanisms are available also for all SortingExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Spike sorting <a class=\"anchor\" id=\"spike-sorting\"></a>\n",
    "\n",
    "We can now run spike sorting on the above recording. We will use different spike sorters for this demonstration, to show how easy SpikeInterface makes it easy to interchengably run different sorters :)\n",
    "\n",
    "Let's first check the installed sorters in `SpikeInterface` to see if `tridesclous` is available. Then we can then check the `tridesclous` default parameters.\n",
    "We will sort the bandpass cached filtered recording the `recording_saved` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "ss.installed_sorters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "default_SC2_params = ss.get_default_sorter_params('kilosort3')\n",
    "# Parameters can be changed by single arguments: \n",
    "#default_TDC_params['detect_threshold'] = 3 \n",
    "#default_TDC_params['freq_max'] = 6000\n",
    "#default_TDC_params['freq_min'] = 300\n",
    "pprint(default_SC2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run spike sorting on entire recording\n",
    "sorting_SC2 = ss.run_sorter('kilosort3', recording_sub, \n",
    "                            output_folder=base_folder / 'results_KS3_7-27-23',\n",
    "                            docker_image=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_SC2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "SpikeInterface ensures full provenance of the spike sorting pipeline. Upon running a spike sorter, a `spikeinterface_params.json` file is saved in the `output_folder`. This contains a `.json` version of the recording and all the input parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can use `spikewidgets` functions for some quick visualizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "w_rs = sw.plot_rasters(sorting_SC2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Extracting waveforms <a class=\"anchor\" id=\"waveforms\"></a>\n",
    "\n",
    "The core module uses `WaveformExtractor` fro extracting waveforms from paired recording-sorting objects. It retrieves waveforms and templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "si.extract_waveforms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_all = si.extract_waveforms(recording_sub, sorting_SC2, folder=base_folder / \"waveforms3m in\", \n",
    "                              max_spikes_per_unit=None, load_if_exists=True, **job_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for unit in sorting_SC2.get_unit_ids():\n",
    "    waveforms = we_all.get_waveforms(unit_id=unit)\n",
    "    spiketrain = sorting_SC2.get_unit_spike_train(unit)\n",
    "    print(f\"Unit {unit} - num waveforms: {waveforms.shape[0]} - num spikes: {len(spiketrain)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now waveforms have been extracted for all spikes! Let's move on to explore the postprocessing capabilities of the `postprocessing` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 7. Postprocessing <a class=\"anchor\" id=\"postprocessing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postprocessing spike sorting results ranges from computing additional information, such as spike amplitudes and Principal Component Analisys (PCA) scores, to computing features of the extracellular waveforms, similarity between templates and crosscorrelograms. All of this is possible with the `postprocessing` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### PCA scores\n",
    "\n",
    "PCA scores can be easily computed with the `compute_principal_components()` function. Similarly to the `extract_waveforms`, the function returns an object of type `WaveformPrincipalComponent` that allows to retrieve all pc scores on demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_all.get_available_extension_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = spost.compute_principal_components(we_all, n_components=3, load_if_exists=True)\n",
    "amplitudes = spost.compute_spike_amplitudes(we_all, outputs=\"by_unit\", load_if_exists=True, \n",
    "                                            **job_kwargs)\n",
    "unit_locations = spost.compute_unit_locations(we_all, method=\"monopolar_triangulation\", load_if_exists=True)\n",
    "spike_locations = spost.compute_spike_locations(we_all, method=\"monopolar_triangulation\", load_if_exists=True,\n",
    "                                                **job_kwargs)\n",
    "ccgs, bins = spost.compute_correlograms(we_all)\n",
    "template_metrics = spost.calculate_template_metrics(we_all)\n",
    "sparsity_radius = spost.get_template_channel_sparsity(we_all, method=\"radius\", radius_um=50)\n",
    "similarity = spost.compute_template_similarity(we_all)\n",
    "\n",
    "qm = sqm.compute_quality_metrics(we_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets\n",
    "sw.plot_unit_locations(we_all, backend=\"ipywidgets\")\n",
    "sw.plot_spike_locations(we_all, backend=\"ipywidgets\")\n",
    "sw.plot_amplitudes(we_all, backend=\"ipywidgets\")\n",
    "sw.plot_autocorrelograms(we_all, unit_ids=sorting_SC2.unit_ids[:4])\n",
    "sw.plot_crosscorrelograms(we_all, unit_ids=sorting_SC2.unit_ids[:4])\n",
    "sw.plot_unit_templates(we_all, backend=\"matplotlib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "isi_viol_thresh = 0.2\n",
    "amp_cutoff_thresh = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A straightforward way to filter a pandas dataframe is via the `query`.\n",
    "We first define our query (make sure the names match the column names of the dataframe):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "our_query = f\"amplitude_cutoff < {amp_cutoff_thresh} & isi_violations_ratio < {isi_viol_thresh}\"\n",
    "print(our_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "and then we can use the query to select units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "keep_units = qm.query(our_query)\n",
    "keep_unit_ids = keep_units.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_auto = sorting_SC2.select_units(keep_unit_ids)\n",
    "print(f\"Number of units before curation: {len(sorting_SC2.get_unit_ids())}\")\n",
    "print(f\"Number of units after curation: {len(sorting_auto.get_unit_ids())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Viewers <a class=\"anchor\" id=\"viewers\"></a>\n",
    "\n",
    "Let's check put the `spikeinterface-gui` to explore our spike sorting results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpikeInterface GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!sigui waveforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Summary - SortingView"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sortingview` backend requires an additional step to configure the transfer of the data to be plotted to the cloud. \n",
    "\n",
    "See documentation [here](https://spikeinterface.readthedocs.io/en/latest/module_widgets.html): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 11. Exporters <a class=\"anchor\" id=\"exporters\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Export to Phy for manual curation\n",
    "\n",
    "To perform manual curation we can export the data to [Phy](https://github.com/cortex-lab/phy). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sexp.export_to_phy(we_all, output_folder=base_folder / 'phy_SC2_RN', compute_pc_features=True,\n",
    "                   copy_binary=True, dtype='float32', compute_amplitudes=True, template_mode='median', verbose=True,**job_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#sexp.export_to_phy(we_all, output_folder=base_folder / 'phy_SC2c', \n",
    "#                   **job_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#%%capture --no-display\n",
    "!phy template-gui phy_SC2_RN/params.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After curating the results we can reload it using the `PhySortingExtractor` and exclude the units that we labeled as `noise`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_phy_curated = se.PhySortingExtractor(base_folder / 'phy_SC2_RN/', exclude_cluster_groups=['noise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of units before curation: {len(sorting_SC2.get_unit_ids())}\")\n",
    "print(f\"Number of units after curation: {len(sorting_phy_curated.get_unit_ids())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('SI-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "e796914cfda0b008681a29da637f213a2ba3e2974d7c5b0074900a81a5c831d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
